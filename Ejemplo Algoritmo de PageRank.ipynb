{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Agradecimientos:** El contenido del siguiente jupyter notebook es la traducción al español del jupyter dispuesto en el siguiente [repositorio](https://github.com/wiqaaas/youtube/tree/master/Machine_Learning_from_Scratch/Search_Engine_Recommender) desarrollado por **Waqas Ahmed**.\n",
    "Aquellas partes resaltadas en *cursivas* son aportes del profesor **Juan C. Correa**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# PageRank\n",
    "Este jupyter supone que usted tiene conocimiento de autovectores y autovalores (*pero acá obviaremos eso por el momento*) y acá se muestra cómo se aplican con el algoritmo PageRank. Este jupyter consta de dos partes. La primera es una hoja de trabajo para que se ponga al día con el funcionamiento del algoritmo; aquí veremos un micro Internet con menos de 10 sitios web y veremos qué hace y qué puede salir mal. La segunda es una evaluación que pondrá a prueba su aplicación de la teoría propia a este problema escribiendo código y calculando el rango de página de una gran red que representa una subsección de Internet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Page Rank en una red de Internet ficticia\n",
    "##### Introducción\n",
    "\n",
    "PageRank (desarrollado por Larry Page y Sergey Brin) revolucionó la búsqueda web al generar una lista clasificada de páginas web basada en la conectividad subyacente de la web. \n",
    "\n",
    "El algoritmo de PageRank se basa en un internauta aleatorio ideal que, al llegar a una página, pasa a la página siguiente haciendo clic en un enlace. \n",
    "\n",
    "El internauta tiene la misma probabilidad de hacer clic en cualquier enlace de la página y, cuando llega a una página sin enlaces, tiene la misma probabilidad de moverse a cualquier otra página escribiendo su URL. \n",
    "\n",
    "Además, el internauta puede optar ocasionalmente por escribir una URL aleatoria en lugar de seguir los enlaces de una página. \n",
    "\n",
    "El PageRank es el orden de clasificación de las páginas desde la página más probable hasta la menos probable que verá el internauta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab notebook\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank como un problema de algebra lineal\n",
    "\n",
    "Imaginemos una pequeña red de Internet con apenas 6 páginas web, como las siguientes (**A**vocado, **B**ullseye, **C**atBabel, **D**romeda, **e**Tings, y **F**aceSpace). Cada página se vincula con algunas otras, y esta serie de conexiones forma una red como la siguiente\n",
    "\n",
    "![A Micro-Internet](internet.png \"A Micro-Internet\")\n",
    "\n",
    "El principio de diseño de PageRank es que los sitios web importantes estarán vinculados por sitios web importantes (*algo relacionado en teoría de redes con el concepto de Homofilia*). Este principio algo recursivo formará la base de nuestro pensamiento.\n",
    "\n",
    "Imagina que tenemos 100 personas procrastinando en una Internet pequeña y cada uno ve un solo sitio web a la vez. Cada minuto, las personas siguen un enlace en su sitio web a otro sitio en esta Internet pequeña. Después de un tiempo, los sitios web a los que están más vinculados tendrán más personas visitándolos y, a la larga, cada minuto por cada persona que abandone un sitio web, entrará otro manteniendo constante el número total de personas en cada sitio web. El PageRank es simplemente la clasificación de los sitios web por la cantidad de personas que tiene cada página al final de este proceso.\n",
    "\n",
    "Representamos el número de Pats en cada sitio web con el vector,\n",
    "\n",
    "$$\\mathbf{r} = \\begin{bmatrix} r_A \\\\ r_B \\\\ r_C \\\\ r_D \\\\ r_E \\\\ r_F \\end{bmatrix}$$\n",
    "Y decimos que el número de personas en cada página web en el minuto $i+1$ está relacionado a aquellos en el minuto $i$ por la matriz de transformación siguiente:\n",
    "\n",
    "$$ \\mathbf{r}^{(i+1)} = L \\,\\mathbf{r}^{(i)}$$\n",
    "with the matrix $L$ taking the form,\n",
    "$$ L = \\begin{bmatrix}\n",
    "L_{A→A} & L_{B→A} & L_{C→A} & L_{D→A} & L_{E→A} & L_{F→A} \\\\\n",
    "L_{A→B} & L_{B→B} & L_{C→B} & L_{D→B} & L_{E→B} & L_{F→B} \\\\\n",
    "L_{A→C} & L_{B→C} & L_{C→C} & L_{D→C} & L_{E→C} & L_{F→C} \\\\\n",
    "L_{A→D} & L_{B→D} & L_{C→D} & L_{D→D} & L_{E→D} & L_{F→D} \\\\\n",
    "L_{A→E} & L_{B→E} & L_{C→E} & L_{D→E} & L_{E→E} & L_{F→E} \\\\\n",
    "L_{A→F} & L_{B→F} & L_{C→F} & L_{D→F} & L_{E→F} & L_{F→F} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "donde las columnas representan la probabilidad de dejar una página para ir a cualquier otra, y sumarle 1. Las filas determinan cuán probable es que usted entre a una página a partir de cualquier otra, aunque estas probabilidades no necesitan sumar uno. El comportamiento a largo plazo de este sistema es cuando se cumple la siguiente igualdad $ \\mathbf{r}^{(i+1)} = \\mathbf{r}^{(i)}$, así que al quitar los sub-indices de esta fórmula podemos escribir,\n",
    "$$ L \\,\\mathbf{r} = \\mathbf{r}$$\n",
    "\n",
    "lo cual es una ecuación de autovalor para la matriz $L$, con autovalor 1 (esto está garantizado por la estructura probabilística de dicha matriz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.array([[0,   1/2, 1/3, 0, 0,   0 ],\n",
    "              [1/3, 0,   0,   0, 1/2, 0 ],\n",
    "              [1/3, 1/2, 0,   1, 0,   1/2 ],\n",
    "              [1/3, 0,   1/3, 0, 1/2, 1/2 ],\n",
    "              [0,   0,   0,   0, 0,   0 ],\n",
    "              [0,   0,   1/3, 0, 0,   0 ]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En principio, podríamos usar una biblioteca de álgebra lineal, como se muestra a continuación, para calcular los valores propios y los vectores. Y esto funcionaría para un sistema pequeño. Pero esto se vuelve inmanejable para sistemas grandes (*aquí entra la magia, la fama, y la reputación de lo que se llama Big Data*). Y dado que solo nos importa el vector propio principal (el que tiene el valor propio más grande, que será 1 en este caso), podemos usar el **método de iteración de potencia** que escalará mejor y es más rápido para sistemas grandes.\n",
    "\n",
    "Utilice el siguiente código para echar un vistazo al PageRank de este micro Internet. (*Ahora sí toca entender intuitivamente qué es un autovalor y un autovector mirando este [video](https://youtu.be/YtgU1ozMgS0)* )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eVals, eVecs = la.eig(L) # Obtenga los autovalores y autovectores\n",
    "order = np.absolute(eVals).argsort()[::-1] # Ordenelos por su autovalores\n",
    "eVals = eVals[order]\n",
    "eVecs = eVecs[:,order]\n",
    "\n",
    "r = eVecs[:, 0] # Defina r como el autovector principal\n",
    "100 * np.real(r / np.sum(r)) # Haga que este autovector sume 1, y luego multipliquelo por 100 (las 100 personas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver en esta lista, la cantidad de personas que esperamos encontrar en cada sitio web después de mucho tiempo. Poniéndolos en orden de popularidad (según esta métrica), el PageRank de este micro Internet es:\n",
    "\n",
    "CatBabel, Dromeda, Aguacate, FaceSpace, Bullseye, eTings\n",
    "\n",
    "Volviendo al diagrama de nuestra pequeña internet, ¿es esto lo que hubiera esperado? Convénzase usted mismo de que, según la importancia aparente de las páginas, en términos de qué otras páginas se enlazan con ellas, esta es una clasificación sensata.\n",
    "\n",
    "Intentemos ahora obtener el mismo resultado usando el método de potencia de iteración que se cubrió en este [video](https://youtu.be/a5zPyhQf7xw). Este método será mucho mejor para trabajar con sistemas grandes.\n",
    "\n",
    "Primero, configuremos nuestro vector inicial, $\\mathbf{r}^{(0)}$, de modo que tengamos las 100 personas distribuidas equitativamente en cada uno de nuestros 6 sitios web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 100 * np.ones(6) / 6 # Sets up this vector (6 entries of 1/6 × 100 each)\n",
    "r # Shows it's value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a actualizar el vector al siguiente minuto con la matriz $L$.\n",
    "Y corremos nuevamente en un loop lo anterior para ver si se estabiliza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(100) : # Repeat 100 times\n",
    "    r = L @ r\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O mejor aún, podemos mantenerOr even better, we can keep running until we get to the required tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 100 * np.ones(6) / 6 # Sets up this vector (6 entries of 1/6 × 100 each)\n",
    "lastR = r\n",
    "r = L @ r\n",
    "i = 0\n",
    "while la.norm(lastR - r) > 0.01 :\n",
    "    lastR = r\n",
    "    r = L @ r\n",
    "    i += 1\n",
    "print(str(i) + \" iterations to convergence.\")\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the PageRank order is established fairly quickly, and the vector converges on the value we calculated earlier after a few tens of repeats.\n",
    "\n",
    "Congratulations! You've just calculated your first PageRank!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Damping Parameter\n",
    "The system we just studied converged fairly quickly to the correct answer.\n",
    "Let's consider an extension to our micro-internet where things start to go wrong.\n",
    "\n",
    "Say a new website is added to the micro-internet: *Geoff's* Website.\n",
    "This website is linked to by *FaceSpace* and only links to itself.\n",
    "![An Expanded Micro-Internet](internet2.png \"An Expanded Micro-Internet\")\n",
    "\n",
    "Intuitively, only *FaceSpace*, which is in the bottom half of the page rank, links to this website amongst the two others it links to,\n",
    "so we might expect *Geoff's* site to have a correspondingly low PageRank score.\n",
    "\n",
    "Build the new $L$ matrix for the expanded micro-internet, and use Power-Iteration on the Procrastinating Pat vector.\n",
    "See what happens…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # We'll call this one L2, to distinguish it from the previous L.\n",
    "L2 = np.array([[0,   1/2, 1/3, 0, 0,   0, 0 ],\n",
    "               [1/3, 0,   0,   0, 1/2, 0, 0 ],\n",
    "               [1/3, 1/2, 0,   1, 0,   0, 0 ],\n",
    "               [1/3, 0,   1/3, 0, 1/2, 0, 0 ],\n",
    "               [0,   0,   0,   0, 0,   0, 0 ],\n",
    "               [0,   0,   1/3, 0, 0,   1, 0 ],\n",
    "               [0,   0,   0,   0, 0,   0, 1 ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 100 * np.ones(7) / 7 # Sets up this vector (7 entries of 1/7 × 100 each)\n",
    "lastR = r\n",
    "r = L2 @ r\n",
    "i = 0\n",
    "while la.norm(lastR - r) > 0.01 :\n",
    "    lastR = r\n",
    "    r = L2 @ r\n",
    "    i += 1\n",
    "print(str(i) + \" iterations to convergence.\")\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's no good! *Geoff* seems to be taking all the traffic on the micro-internet, and somehow coming at the top of the PageRank.\n",
    "This behaviour can be understood, because once a Pat get's to *Geoff's* Website, they can't leave, as all links head back to Geoff.\n",
    "\n",
    "To combat this, we can add a small probability that the Procrastinating Pats don't follow any link on a webpage, but instead visit a website on the micro-internet at random.\n",
    "We'll say the probability of them following a link is $d$ and the probability of choosing a random website is therefore $1-d$.\n",
    "We can use a new matrix to work out where the Pat's visit each minute.\n",
    "$$ M = d \\, L + \\frac{1-d}{n} \\, J $$\n",
    "where $J$ is an $n\\times n$ matrix where every element is one.\n",
    "\n",
    "If $d$ is one, we have the case we had previously, whereas if $d$ is zero, we will always visit a random webpage and therefore all webpages will be equally likely and equally ranked.\n",
    "For this extension to work best, $1-d$ should be somewhat small - though we won't go into a discussion about exactly how small.\n",
    "\n",
    "Let's retry this PageRank with this extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 0.5 # Feel free to play with this parameter after running the code once.\n",
    "M = d * L2 + (1-d)/7 * np.ones([7, 7]) # np.ones() is the J matrix, with ones for each entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 100 * np.ones(7) / 7 # Sets up this vector (6 entries of 1/6 × 100 each)\n",
    "lastR = r\n",
    "r = M @ r\n",
    "i = 0\n",
    "while la.norm(lastR - r) > 0.01 :\n",
    "    lastR = r\n",
    "    r = M @ r\n",
    "    i += 1\n",
    "print(str(i) + \" iterations to convergence.\")\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is certainly better, the PageRank gives sensible numbers for the Procrastinating Pats that end up on each webpage.\n",
    "This method still predicts Geoff has a high ranking webpage however.\n",
    "This could be seen as a consequence of using a small network. We could also get around the problem by not counting self-links when producing the L matrix (an if a website has no outgoing links, make it link to all websites equally).\n",
    "We won't look further down this route, as this is in the realm of improvements to PageRank, rather than eigenproblems.\n",
    "\n",
    "You are now in a good position, having gained an understanding of PageRank, to produce your own code to calculate the PageRank of a website with thousands of entries.\n",
    "\n",
    "Good Luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sub Internet Page Ranking\n",
    "In this assessment, you will be asked to produce a function that can calculate the PageRank for an arbitrarily large probability matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this function to provide the PageRank for an arbitrarily sized internet.\n",
    "# I.e. the principal eigenvector of the damped system, using the power iteration method.\n",
    "# (Normalisation doesn't matter here)\n",
    "# The functions inputs are the linkMatrix, and d the damping parameter - as defined in this worksheet.\n",
    "def pageRank(linkMatrix, d) :\n",
    "    n = linkMatrix.shape[0]\n",
    "    M = d * linkMatrix + (1-d)/n * np.ones([n, n])\n",
    "    r = 100 * np.ones(n) / n # Sets up this vector (n entries of 1/n × 100 each)\n",
    "    last = r\n",
    "    r = M @ r\n",
    "    while la.norm(last - r) > 0.01 :\n",
    "        last = r\n",
    "        r = M @ r\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_internet(n) :\n",
    "    c = np.full([n,n], np.arange(n))\n",
    "    c = (abs(np.random.standard_cauchy([n,n])/2) > (np.abs(c - c.T) + 1)) + 0\n",
    "    c = (c+1e-10) / np.sum((c+1e-10), axis=0)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following function to generate internets of different sizes.\n",
    "generate_internet(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your PageRank method against the built in \"eig\" method.\n",
    "# You should see yours is a lot faster for large internets\n",
    "L = generate_internet(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageRank(L, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do note, this is calculating the eigenvalues of the link matrix, L,\n",
    "# without any damping. It may give different results that your pageRank function.\n",
    "# If you wish, you could modify this cell to include damping.\n",
    "eVals, eVecs = la.eig(L) # Gets the eigenvalues and vectors\n",
    "order = np.absolute(eVals).argsort()[::-1] # Orders them by their eigenvalues\n",
    "eVals = eVals[order]\n",
    "eVecs = eVecs[:,order]\n",
    "\n",
    "r = eVecs[:, 0]\n",
    "100 * np.real(r / np.sum(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may wish to view the PageRank graphically.\n",
    "# This code will draw a bar chart, for each (numbered) website on the generated internet,\n",
    "# The height of each bar will be the score in the PageRank.\n",
    "# Run this code to see the PageRank for each internet you generate.\n",
    "# Hopefully you should see what you might expect\n",
    "# - there are a few clusters of important websites, but most on the internet are rubbish!\n",
    "%pylab notebook\n",
    "r = pageRank(generate_internet(100), 0.9)\n",
    "plt.bar(arange(r.shape[0]), r);"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "linear-algebra-machine-learning",
   "graded_item_id": "Sfbnp",
   "launcher_item_id": "aPxf3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
