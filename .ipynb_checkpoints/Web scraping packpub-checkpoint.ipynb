{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a6759ba",
   "metadata": {},
   "source": [
    "Este jupyter notebook nos ayudará a entender qué es hacer web scraping en una página web desde un punto de vista práctico. El contenido de este jupyter notebook ha sido adaptado del capítulo 8 del libro de texto ***Getting Started with Beautiful Soup*** de Vineeth G. Nair (2014)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7930df",
   "metadata": {},
   "source": [
    "# Primer Paso: \n",
    "## Definir cuál es la página web desde donde vamos a extraer los datos\n",
    "\n",
    "Aquí vamos a utilizar la página web [packtpub.com](https://www.packtpub.com/). Sobre esta página el scraper que construiremos nos permitirá extraer los datos del precio de una lista de libros vendidos en esa página web y buscar en otras páginas como [amazon.com](www.amazon.com) o [barnes and nobles](www.barnesandnobles.com) empleando el ISBN de cada libro (el ISBN de un libro es el equivalente a la cédula de identidad de una persona. Ayuda a identificar inequívocamente al libro)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84174cb6",
   "metadata": {},
   "source": [
    "# Segundo Paso:\n",
    "\n",
    "## Explorar el contenido de la página web \n",
    "\n",
    "En este caso, solo vamos a concentrarnos en el título de cada libro, su precio de venta y su ISBN. Para explorar el contenido, primero ingresamos a la página web con un navegador y miramos su contenido como lo hacemos usualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a58b07d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "packtpub_url = 'https://www.packtpub.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d7bf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bookurls(url):\n",
    "    page = urllib.request.urlopen(url)\n",
    "    soup_packtpage = BeautifulSoup(page, 'lxml')\n",
    "    page.close()\n",
    "    next_page_li = soup_packtpage.find(\"li\", class_=\"pager-nextlast\")\n",
    "    if next_page_li is None:\n",
    "        next_page_url = None\n",
    "    else:\n",
    "            next_page_url = packtpub_url+next_page_li.a.get('href')\n",
    "            \n",
    "    return next_page_url"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
